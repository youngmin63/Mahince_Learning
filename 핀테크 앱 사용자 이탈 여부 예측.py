# -*- coding: utf-8 -*-
"""2churn_Template_with_Guide.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y_U-K8OHANIrbQlOQ6rYjlsAf34DYBF7

# 📉 핀테크 사용자 이탈 예측 템플릿
목적: 사용자 행동 및 서비스 이용 정보를 바탕으로 핀테크 앱 사용자 이탈(user_churn) 여부를 예측하는 분류 모델을 구축

###  핀테크 앱 사용자 이탈 예측

📌 **제출 항목 구성 예시**

#### 1. 데이터 전처리
- **불필요한 컬럼 제거**  
  - `user_id`는 예측에 불필요하므로 제거
- **범주형 변수 인코딩**  
  - `preferred_channel`, `membership_type`, `preferred_payment_type`, `app_security_enabled`, `in_app_support_use` 등
- **연속형 변수 스케일링**  
  - `months_active`, `monthly_spending`, `total_transaction_amt` 등에 `StandardScaler` 또는 `MinMaxScaler` 적용
- **X와 y 분할**  
  - 타깃 변수 `user_churn` (0: 유지, 1: 이탈), 나머지를 X로 설정

#### 2. 탐색적 데이터 분석 (EDA)
- 이탈 고객과 유지 고객 간 주요 변수 차이 시각화  
  - 예: `monthly_spending`, `months_active`, `membership_type`별 이탈률 비교
- 이탈 비율, 분포 불균형 여부 확인

#### 3. 모델링 및 성능 평가
- 2가지 이상 분류 모델 적용  
  - 예: `LogisticRegression`, `RandomForestClassifier` 등
- `train_test_split` 후 모델 학습
- 정확도(accuracy), 재현율(recall), 정밀도(precision), F1-score 등 평가 지표 출력
- **Confusion Matrix**와 **ROC Curve** 시각화

#### 4. 변수 중요도 분석
- 모델 계수 또는 feature importance를 시각화
- `membership_type`, `preferred_channel`, `spending` 등이 이탈에 미치는 영향 해석

#### 5. 결과 해석
- 고객 이탈을 예측하는 데 가장 중요한 변수는 무엇인가?
- 핀테크 앱 사용자 이탈을 줄이기 위한 시사점 제시

### ✅ 변수 설명 (핀테크 사용자 이탈 예측 데이터)

| 변수명 | 설명 |
|--------|------|
| `user_id` | 사용자 고유 ID |
| `months_active` | 핀테크 앱을 사용한 누적 개월 수 |
| `monthly_spending` | 월 평균 결제 금액 |
| `total_transaction_amt` | 전체 누적 결제 금액 |
| `preferred_channel` | 주 이용 채널 (예: mobile, web) |
| `membership_type` | 멤버십 유형 (free, standard, premium) |
| `preferred_payment_type` | 선호 결제 방식 (card, simple_pay, auto_transfer 등) |
| `app_security_enabled` | 보안 기능 사용 여부 (예: 생체인증 등) |
| `in_app_support_use` | 앱 내 고객지원 기능 이용 여부 |
| `user_churn` | 사용자 이탈 여부 (1: 이탈, 0: 유지) |
"""

# 📦 라이브러리 불러오기
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from Sklearn.linear_model import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix

# 📥 데이터 불러오기
df = pd.read_csv('fintech_user_churn.csv')
df.head()

# 🧹 전처리: 범주형 변수 인코딩 및 분할
df_encoded = pd.get_dummies(df.drop('user_id', axis=1), drop_first=True)
X = df_encoded.drop('user_churn', axis=1)
y = df_encoded['user_churn']

scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3, random_state=42)

# 🤖 로지스틱 회귀 모델 학습 및 예측
model = LogisticRegression(max_iter=1000)
model.fit(X_train, y_train)
y_pred = model.predict(X_test)

# 📊 평가 결과 출력
print(classification_report(y_test, y_pred))
sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d')
plt.title('Confusion Matrix')
plt.show()

model=RandomForestClassifier()
model.fit(X_train,y_train)
y_pred=model.predict(X_test)

"""## 📌 결과 해석
- 어떤 요인이 이탈 여부에 영향을 주었는가?
- recall과 precision 중 어떤 지표가 더 중요한가?
- 모델 성능 개선을 위해 어떤 기법을 추가할 수 있을까?
"""